{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mqwQfQOOZAYL",
        "outputId": "e0b859ce-ed7b-4ae6-b451-d3a8328c9cbf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hit:1 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:2 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Get:3 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,632 B]\n",
            "Hit:4 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Get:6 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "Hit:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Get:10 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [8,802 kB]\n",
            "Hit:11 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:12 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [2,773 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [4,126 kB]\n",
            "Get:14 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [3,972 kB]\n",
            "Get:15 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,685 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [3,081 kB]\n",
            "Get:17 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,241 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,540 kB]\n",
            "Fetched 28.6 MB in 7s (4,211 kB/s)\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  libnvinfer-headers-dev libnvinfer-headers-plugin-dev libnvinfer-plugin10 libnvinfer10\n",
            "The following NEW packages will be installed:\n",
            "  libnvinfer-dev libnvinfer-headers-dev libnvinfer-headers-plugin-dev libnvinfer-plugin-dev\n",
            "  libnvinfer-plugin10 libnvinfer10\n",
            "0 upgraded, 6 newly installed, 0 to remove and 39 not upgraded.\n",
            "Need to get 4,017 MB of archives.\n",
            "After this operation, 9,997 MB of additional disk space will be used.\n",
            "Get:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  libnvinfer-headers-dev 10.9.0.34-1+cuda12.8 [109 kB]\n",
            "Get:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  libnvinfer10 10.9.0.34-1+cuda12.8 [1,968 MB]\n",
            "Get:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  libnvinfer-dev 10.9.0.34-1+cuda12.8 [2,020 MB]\n",
            "Get:4 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  libnvinfer-headers-plugin-dev 10.9.0.34-1+cuda12.8 [6,056 B]\n",
            "Get:5 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  libnvinfer-plugin10 10.9.0.34-1+cuda12.8 [13.7 MB]\n",
            "Get:6 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  libnvinfer-plugin-dev 10.9.0.34-1+cuda12.8 [15.0 MB]\n",
            "Fetched 4,017 MB in 60s (66.6 MB/s)\n",
            "Selecting previously unselected package libnvinfer-headers-dev.\n",
            "(Reading database ... 126210 files and directories currently installed.)\n",
            "Preparing to unpack .../0-libnvinfer-headers-dev_10.9.0.34-1+cuda12.8_amd64.deb ...\n",
            "Unpacking libnvinfer-headers-dev (10.9.0.34-1+cuda12.8) ...\n",
            "Selecting previously unselected package libnvinfer10.\n",
            "Preparing to unpack .../1-libnvinfer10_10.9.0.34-1+cuda12.8_amd64.deb ...\n",
            "Unpacking libnvinfer10 (10.9.0.34-1+cuda12.8) ...\n",
            "Selecting previously unselected package libnvinfer-dev.\n",
            "Preparing to unpack .../2-libnvinfer-dev_10.9.0.34-1+cuda12.8_amd64.deb ...\n",
            "Unpacking libnvinfer-dev (10.9.0.34-1+cuda12.8) ...\n",
            "Selecting previously unselected package libnvinfer-headers-plugin-dev.\n",
            "Preparing to unpack .../3-libnvinfer-headers-plugin-dev_10.9.0.34-1+cuda12.8_amd64.deb ...\n",
            "Unpacking libnvinfer-headers-plugin-dev (10.9.0.34-1+cuda12.8) ...\n",
            "Selecting previously unselected package libnvinfer-plugin10.\n",
            "Preparing to unpack .../4-libnvinfer-plugin10_10.9.0.34-1+cuda12.8_amd64.deb ...\n",
            "Unpacking libnvinfer-plugin10 (10.9.0.34-1+cuda12.8) ...\n",
            "Selecting previously unselected package libnvinfer-plugin-dev.\n",
            "Preparing to unpack .../5-libnvinfer-plugin-dev_10.9.0.34-1+cuda12.8_amd64.deb ...\n",
            "Unpacking libnvinfer-plugin-dev (10.9.0.34-1+cuda12.8) ...\n",
            "Setting up libnvinfer-headers-dev (10.9.0.34-1+cuda12.8) ...\n",
            "Setting up libnvinfer10 (10.9.0.34-1+cuda12.8) ...\n",
            "Setting up libnvinfer-plugin10 (10.9.0.34-1+cuda12.8) ...\n",
            "Setting up libnvinfer-dev (10.9.0.34-1+cuda12.8) ...\n",
            "Setting up libnvinfer-headers-plugin-dev (10.9.0.34-1+cuda12.8) ...\n",
            "Setting up libnvinfer-plugin-dev (10.9.0.34-1+cuda12.8) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.8) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libumf.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "Collecting onnx\n",
            "  Downloading onnx-1.17.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (16 kB)\n",
            "Collecting onnxruntime\n",
            "  Downloading onnxruntime-1.21.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.5 kB)\n",
            "Collecting tensorrt\n",
            "  Downloading tensorrt-10.9.0.34.tar.gz (40 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m40.7/40.7 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting onnx_graphsurgeon\n",
            "  Downloading onnx_graphsurgeon-0.5.7-py2.py3-none-any.whl.metadata (8.2 kB)\n",
            "Collecting fastapi\n",
            "  Downloading fastapi-0.115.12-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting uvicorn\n",
            "  Downloading uvicorn-0.34.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.11/dist-packages (1.6.0)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.11/dist-packages (from onnx) (2.0.2)\n",
            "Requirement already satisfied: protobuf>=3.20.2 in /usr/local/lib/python3.11/dist-packages (from onnx) (5.29.4)\n",
            "Collecting coloredlogs (from onnxruntime)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime) (25.2.10)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from onnxruntime) (24.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from onnxruntime) (1.13.1)\n",
            "Collecting tensorrt_cu12==10.9.0.34 (from tensorrt)\n",
            "  Downloading tensorrt_cu12-10.9.0.34.tar.gz (18 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting tensorrt_cu12_libs==10.9.0.34 (from tensorrt_cu12==10.9.0.34->tensorrt)\n",
            "  Downloading tensorrt_cu12_libs-10.9.0.34.tar.gz (704 bytes)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting tensorrt_cu12_bindings==10.9.0.34 (from tensorrt_cu12==10.9.0.34->tensorrt)\n",
            "  Downloading tensorrt_cu12_bindings-10.9.0.34-cp311-none-manylinux_2_28_x86_64.whl.metadata (606 bytes)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12 in /usr/local/lib/python3.11/dist-packages (from tensorrt_cu12_libs==10.9.0.34->tensorrt_cu12==10.9.0.34->tensorrt) (12.5.82)\n",
            "Collecting onnx\n",
            "  Downloading onnx-1.16.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (16 kB)\n",
            "Collecting starlette<0.47.0,>=0.40.0 (from fastapi)\n",
            "  Downloading starlette-0.46.1-py3-none-any.whl.metadata (6.2 kB)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from fastapi) (2.11.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from fastapi) (4.13.0)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.11/dist-packages (from uvicorn) (8.1.8)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.11/dist-packages (from uvicorn) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (2.33.0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (0.4.0)\n",
            "Requirement already satisfied: anyio<5,>=3.6.2 in /usr/local/lib/python3.11/dist-packages (from starlette<0.47.0,>=0.40.0->fastapi) (4.9.0)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->onnxruntime) (1.3.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.6.2->starlette<0.47.0,>=0.40.0->fastapi) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.6.2->starlette<0.47.0,>=0.40.0->fastapi) (1.3.1)\n",
            "Downloading onnxruntime-1.21.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.0 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m16.0/16.0 MB\u001b[0m \u001b[31m86.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorrt_cu12_bindings-10.9.0.34-cp311-none-manylinux_2_28_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m64.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnx_graphsurgeon-0.5.7-py2.py3-none-any.whl (57 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m57.9/57.9 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnx-1.16.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (15.9 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m15.9/15.9 MB\u001b[0m \u001b[31m85.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fastapi-0.115.12-py3-none-any.whl (95 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m95.2/95.2 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading uvicorn-0.34.0-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading starlette-0.46.1-py3-none-any.whl (71 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: tensorrt, tensorrt_cu12, tensorrt_cu12_libs\n",
            "  Building wheel for tensorrt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tensorrt: filename=tensorrt-10.9.0.34-py2.py3-none-any.whl size=46629 sha256=ef68751c75d9ae4655779018fa62582e9cddf63b064047b1e6c145a527907251\n",
            "  Stored in directory: /root/.cache/pip/wheels/3a/4d/72/f28cb367f1435d026243047d4f60fde8f1c9cbb06a204f842f\n",
            "  Building wheel for tensorrt_cu12 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tensorrt_cu12: filename=tensorrt_cu12-10.9.0.34-py2.py3-none-any.whl size=17466 sha256=5c87a6ecfab198a2ca1cb9ec7151c604d6af1333fc8b4a41d555df4a7d7eeca9\n",
            "  Stored in directory: /root/.cache/pip/wheels/75/09/76/6b405075fe4c04097f5713ec0a688df7892aaee823bc141952\n",
            "  Building wheel for tensorrt_cu12_libs (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tensorrt_cu12_libs: filename=tensorrt_cu12_libs-10.9.0.34-py2.py3-none-manylinux_2_28_x86_64.whl size=3103291777 sha256=4a82f0bda2874596f202f6edc8dae99b86a3c4ec2fa142a9c847c4d3a57864a0\n",
            "  Stored in directory: /root/.cache/pip/wheels/33/d0/06/35d7b3006eead25828debb658da848328ebfd38962a2bcd096\n",
            "Successfully built tensorrt tensorrt_cu12 tensorrt_cu12_libs\n",
            "Installing collected packages: tensorrt_cu12_bindings, uvicorn, tensorrt_cu12_libs, onnx, humanfriendly, tensorrt_cu12, starlette, onnx_graphsurgeon, coloredlogs, tensorrt, onnxruntime, fastapi\n",
            "Successfully installed coloredlogs-15.0.1 fastapi-0.115.12 humanfriendly-10.0 onnx-1.16.1 onnx_graphsurgeon-0.5.7 onnxruntime-1.21.0 starlette-0.46.1 tensorrt-10.9.0.34 tensorrt_cu12-10.9.0.34 tensorrt_cu12_bindings-10.9.0.34 tensorrt_cu12_libs-10.9.0.34 uvicorn-0.34.0\n",
            "Requirement already satisfied: fastapi in /usr/local/lib/python3.11/dist-packages (0.115.12)\n",
            "Requirement already satisfied: uvicorn in /usr/local/lib/python3.11/dist-packages (0.34.0)\n",
            "Collecting pyngrok\n",
            "  Downloading pyngrok-7.2.3-py3-none-any.whl.metadata (8.7 kB)\n",
            "Collecting pycuda\n",
            "  Downloading pycuda-2025.1.tar.gz (1.7 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m26.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (11.1.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Requirement already satisfied: tensorrt in /usr/local/lib/python3.11/dist-packages (10.9.0.34)\n",
            "Collecting python-multipart\n",
            "  Downloading python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: starlette<0.47.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from fastapi) (0.46.1)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from fastapi) (2.11.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from fastapi) (4.13.0)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.11/dist-packages (from uvicorn) (8.1.8)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.11/dist-packages (from uvicorn) (0.14.0)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.11/dist-packages (from pyngrok) (6.0.2)\n",
            "Collecting pytools>=2011.2 (from pycuda)\n",
            "  Downloading pytools-2025.1.2-py3-none-any.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: platformdirs>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from pycuda) (4.3.7)\n",
            "Requirement already satisfied: mako in /usr/lib/python3/dist-packages (from pycuda) (1.1.3)\n",
            "Requirement already satisfied: tensorrt-cu12==10.9.0.34 in /usr/local/lib/python3.11/dist-packages (from tensorrt) (10.9.0.34)\n",
            "Requirement already satisfied: tensorrt-cu12-libs==10.9.0.34 in /usr/local/lib/python3.11/dist-packages (from tensorrt-cu12==10.9.0.34->tensorrt) (10.9.0.34)\n",
            "Requirement already satisfied: tensorrt-cu12-bindings==10.9.0.34 in /usr/local/lib/python3.11/dist-packages (from tensorrt-cu12==10.9.0.34->tensorrt) (10.9.0.34)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12 in /usr/local/lib/python3.11/dist-packages (from tensorrt-cu12-libs==10.9.0.34->tensorrt-cu12==10.9.0.34->tensorrt) (12.5.82)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (2.33.0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (0.4.0)\n",
            "Requirement already satisfied: anyio<5,>=3.6.2 in /usr/local/lib/python3.11/dist-packages (from starlette<0.47.0,>=0.40.0->fastapi) (4.9.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.6.2->starlette<0.47.0,>=0.40.0->fastapi) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.6.2->starlette<0.47.0,>=0.40.0->fastapi) (1.3.1)\n",
            "Downloading pyngrok-7.2.3-py3-none-any.whl (23 kB)\n",
            "Downloading python_multipart-0.0.20-py3-none-any.whl (24 kB)\n",
            "Downloading pytools-2025.1.2-py3-none-any.whl (92 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m92.9/92.9 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: pycuda\n",
            "  Building wheel for pycuda (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pycuda: filename=pycuda-2025.1-cp311-cp311-linux_x86_64.whl size=660425 sha256=b57bef71abcf672a72053e76bc1d1165c0aff869b38f017b885f600ea39e7dc3\n",
            "  Stored in directory: /root/.cache/pip/wheels/77/7e/6c/d2d1451ea6424cdc3d67b36c16fa7111eafdf2034bc3405666\n",
            "Successfully built pycuda\n",
            "Installing collected packages: pytools, python-multipart, pyngrok, pycuda\n",
            "Successfully installed pycuda-2025.1 pyngrok-7.2.3 python-multipart-0.0.20 pytools-2025.1.2\n"
          ]
        }
      ],
      "source": [
        "# install dependencies\n",
        "!apt-get update && apt-get install -y libnvinfer-dev libnvinfer-plugin-dev\n",
        "!pip install onnx onnxruntime tensorrt onnx_graphsurgeon fastapi uvicorn nest-asyncio\n",
        "!pip install fastapi uvicorn pyngrok pycuda pillow numpy tensorrt python-multipart"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bDW6FCCGI_OS",
        "outputId": "4bf017a3-f736-4dd0-9043-4c8bf6e73883"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "ğŸ”¹ Running ONNX model benchmark...\n",
            "\n",
            "ğŸ”¹ Running TensorRT model benchmark...\n",
            "\n",
            "âœ… Benchmark Results:\n",
            "Metric                   ONNX Model          TensorRT Model\n",
            "======================================================================\n",
            "Batch Size               8                   8\n",
            "Avg Latency (ms)         888.73              8.69\n",
            "Throughput (img/sec)     9.00                920.63\n",
            "Avg GPU Usage (%)        20.44               20.20\n",
            "Avg Memory Usage (MB)    -1.48               0.00\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "import os\n",
        "import psutil\n",
        "import numpy as np\n",
        "import onnxruntime as ort\n",
        "import tensorrt as trt\n",
        "import pycuda.driver as cuda\n",
        "import pycuda.autoinit\n",
        "from PIL import Image\n",
        "\n",
        "# Paths\n",
        "onnx_model_path = \"/content/resnet50_dog_cat.onnx\"\n",
        "tensorrt_engine_path = \"/content/resnet50_dog_cat.trt\"\n",
        "image_folder = \"/content/test_images\"\n",
        "\n",
        "# Load ONNX model with GPU provider\n",
        "onnx_session = ort.InferenceSession(onnx_model_path, providers=[\"CUDAExecutionProvider\"])\n",
        "onnx_input_name = onnx_session.get_inputs()[0].name\n",
        "\n",
        "# Load TensorRT engine\n",
        "def load_trt_engine(engine_path):\n",
        "    TRT_LOGGER = trt.Logger(trt.Logger.WARNING)\n",
        "    with open(engine_path, \"rb\") as f, trt.Runtime(TRT_LOGGER) as runtime:\n",
        "        return runtime.deserialize_cuda_engine(f.read())\n",
        "\n",
        "tensorrt_engine = load_trt_engine(tensorrt_engine_path)\n",
        "context = tensorrt_engine.create_execution_context()\n",
        "\n",
        "def preprocess_image(image_path):\n",
        "    image = Image.open(image_path).convert(\"RGB\")\n",
        "    image = image.resize((224, 224))\n",
        "    image_array = np.asarray(image).astype(np.float32) / 255.0\n",
        "    image_array = np.transpose(image_array, (2, 0, 1))\n",
        "    image_array = np.expand_dims(image_array, axis=0)\n",
        "    return image_array\n",
        "\n",
        "def load_batch_images(image_folder, batch_size=8):\n",
        "    image_files = [os.path.join(image_folder, f) for f in os.listdir(image_folder) if f.endswith((\"jpg\", \"png\"))]\n",
        "    images = [preprocess_image(img) for img in image_files[:batch_size]]\n",
        "    images = np.vstack(images)\n",
        "    return images, image_files[:batch_size]\n",
        "\n",
        "def run_onnx_inference(session, images, input_name):\n",
        "    return session.run(None, {input_name: images})[0]\n",
        "\n",
        "def run_trt_inference(engine, context, images):\n",
        "    # Ensure the input array is contiguous\n",
        "    images = np.ascontiguousarray(images) # This line is added to make the array contiguous\n",
        "\n",
        "    d_input = cuda.mem_alloc(images.nbytes)\n",
        "    d_output = cuda.mem_alloc(images.nbytes)\n",
        "    bindings = [int(d_input), int(d_output)]\n",
        "    stream = cuda.Stream()\n",
        "\n",
        "    cuda.memcpy_htod_async(d_input, images, stream)\n",
        "    # Changed from execute_async_v2 to execute_v2\n",
        "    context.execute_v2(bindings=bindings)\n",
        "    output = np.empty_like(images)\n",
        "    cuda.memcpy_dtoh_async(output, d_output, stream)\n",
        "    stream.synchronize()\n",
        "    return output\n",
        "\n",
        "def benchmark_model(session, context, images, input_name, model_name, num_runs=50):\n",
        "    times, gpu_usages, memory_usages = [], [], []\n",
        "\n",
        "    for _ in range(num_runs):\n",
        "        start_time = time.time()\n",
        "        start_gpu = psutil.virtual_memory().percent\n",
        "        start_memory = psutil.virtual_memory().used / (1024 * 1024)\n",
        "\n",
        "        if model_name == \"ONNX\":\n",
        "            result = run_onnx_inference(session, images, input_name)\n",
        "        else:\n",
        "            result = run_trt_inference(tensorrt_engine, context, images)\n",
        "\n",
        "        end_time = time.time()\n",
        "        end_gpu = psutil.virtual_memory().percent\n",
        "        end_memory = psutil.virtual_memory().used / (1024 * 1024)\n",
        "\n",
        "        times.append((end_time - start_time) * 1000)\n",
        "        gpu_usages.append(end_gpu)\n",
        "        memory_usages.append(end_memory - start_memory)\n",
        "\n",
        "    avg_latency = np.mean(times)\n",
        "    avg_throughput = (len(images) * num_runs) / (np.sum(times) / 1000)\n",
        "    avg_gpu = np.mean(gpu_usages)\n",
        "    avg_memory = np.mean(memory_usages)\n",
        "\n",
        "    return avg_latency, avg_throughput, avg_gpu, avg_memory\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    batch_size = 8\n",
        "    num_runs = 50\n",
        "\n",
        "    images, _ = load_batch_images(image_folder, batch_size)\n",
        "\n",
        "    print(\"\\nğŸ”¹ Running ONNX model benchmark...\")\n",
        "    onnx_metrics = benchmark_model(onnx_session, None, images, onnx_input_name, \"ONNX\", num_runs)\n",
        "\n",
        "    print(\"\\nğŸ”¹ Running TensorRT model benchmark...\")\n",
        "    tensorrt_metrics = benchmark_model(None, context, images, None, \"TensorRT\", num_runs)\n",
        "\n",
        "    print(\"\\nâœ… Benchmark Results:\")\n",
        "    print(f\"{'Metric':<25}{'ONNX Model':<20}{'TensorRT Model'}\")\n",
        "    print(\"=\"*70)\n",
        "    print(f\"{'Batch Size':<25}{batch_size:<20}{batch_size}\")\n",
        "    print(f\"{'Avg Latency (ms)':<25}{onnx_metrics[0]:<20.2f}{tensorrt_metrics[0]:.2f}\")\n",
        "    print(f\"{'Throughput (img/sec)':<25}{onnx_metrics[1]:<20.2f}{tensorrt_metrics[1]:.2f}\")\n",
        "    print(f\"{'Avg GPU Usage (%)':<25}{onnx_metrics[2]:<20.2f}{tensorrt_metrics[2]:.2f}\")\n",
        "    print(f\"{'Avg Memory Usage (MB)':<25}{onnx_metrics[3]:<20.2f}{tensorrt_metrics[3]:.2f}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
